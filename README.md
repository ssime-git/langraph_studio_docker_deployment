# ğŸš€ LangGraph Docker Stack - Tout-en-un

Une solution Docker complÃ¨te pour dÃ©velopper, tester et dÃ©ployer des agents LangGraph **sans aucune installation locale** (sauf Docker).

## âœ¨ CaractÃ©ristiques

- **Zero installation** : Juste `docker-compose up` et c'est parti!
- **Interface web locale** : CrÃ©ez et Ã©ditez vos agents directement dans le navigateur
- **Stack complÃ¨te** : PostgreSQL, Redis, API LangGraph, Interface web
- **Compatible Studio** : Fonctionne avec LangGraph Studio officiel
- **Mode dÃ©veloppeur** : Pas besoin de licence pour tester

## ğŸ“¦ Ce qui est inclus

1. **LangGraph API Server** : Le serveur principal qui exÃ©cute vos agents
2. **PostgreSQL** : Base de donnÃ©es pour la persistence
3. **Redis** : Gestion des tÃ¢ches et streaming
4. **Interface Web** : Ã‰diteur d'agents avec Monaco Editor
5. **Nginx Proxy** : Routing propre entre les services

## ğŸ DÃ©marrage rapide

### 1. Configuration

CrÃ©ez un fichier `.env` avec votre clÃ© API:

```bash
OPENAI_API_KEY=sk-...
# ou
ANTHROPIC_API_KEY=sk-ant-...
```

### 2. Lancer la stack

```bash
# MÃ©thode 1: Avec le script
chmod +x start.sh
./start.sh

# MÃ©thode 2: Directement avec docker-compose
docker-compose up -d
```

### 3. AccÃ©der aux interfaces

- **Interface Studio Local**: http://localhost
- **API LangGraph**: http://localhost:8123
- **Documentation API**: http://localhost:8123/docs

## ğŸ¨ Interface Web Locale

L'interface web locale permet de:

### CrÃ©er des agents
1. Cliquez sur "+ Nouvel Agent"
2. Donnez un nom Ã  votre agent
3. L'Ã©diteur s'ouvre avec un template de base

### Ã‰diter le code
- Ã‰diteur Monaco (mÃªme que VS Code)
- Coloration syntaxique Python
- Auto-complÃ©tion de base

### Tester les agents
1. SÃ©lectionnez l'onglet "Test"
2. Entrez un JSON d'entrÃ©e
3. Cliquez sur "ExÃ©cuter Test"
4. Voyez le rÃ©sultat en temps rÃ©el


### Exemple d'agent minimal

Utilisez la syntaxe suivante pour que Studio dÃ©tecte le mode Chat:

- messages dans l'Ã©tat: `messages: Annotated[List[BaseMessage], add_messages]`
- retourner des messages `AIMessage`/`HumanMessage` depuis le nÅ“ud
- compiler le graphe et exposer `app`

**agent.py**:
```python
# agent.py
from typing import TypedDict, Annotated, List
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import AIMessage, HumanMessage, BaseMessage

class State(TypedDict):
    # Strongly typed messages so schema includes LC message structure
    messages: Annotated[List[BaseMessage], add_messages]

def agent_node(state: State):
    last_user = None
    # Handle both LC messages and dicts defensively
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            last_user = m.content
            break
        if isinstance(m, dict) and m.get("role") == "user":
            last_user = m.get("content", "")
            break
    reply = f"Echo: {last_user}" if last_user else "Hello from echo agent"
    return {"messages": [AIMessage(content=reply)]}

graph = StateGraph(State)
graph.add_node("agent", agent_node)
graph.set_entry_point("agent")
graph.add_edge("agent", END)
app = graph.compile()
```

## ğŸ”Œ IntÃ©gration avec LangGraph Studio

Si vous prÃ©fÃ©rez utiliser LangGraph Studio officiel:

1. Assurez-vous que l'API est lancÃ©e (port 8123)
2. Si le Chat ne fonctionne pas avec le port 8123, utilisez le proxy Nginx (qui ajoute les en-tÃªtes CORS): https://smith.langchain.com/studio/?baseUrl=http://localhost:8123

On peut aussi utiliser (chemin par NGINX) https://smith.langchain.com/studio/?baseUrl=http://localhost:8080 ou https://smith.langchain.com/studio/?baseUrl=http://localhost/api

3. Ajoutez votre clÃ© LangSmith cÃ´tÃ© API: export LANGSMITH_API_KEY=... (ou dans `.env`) afin d'activer l'affichage des runs
4. Studio se connectera Ã  votre serveur local

## ğŸŒ Interfaces & URLs

- __UI locale (Ã©diteur dâ€™agents)__ â€” http://localhost
  - CrÃ©er/Ã©diter les agents dans `agents/`
  - Tester via lâ€™onglet "Test" (appelle lâ€™API en local)

- __API LangGraph__ â€” http://localhost:8123
  - Câ€™est une API, pas un site. La racine `/` renvoie "Not Found" (normal)
  - Documentation interactive: http://localhost:8123/docs
  - UtilisÃ©e par lâ€™UI locale et par LangGraph Studio

- __LangGraph Studio (cloud)__ â€” https://smith.langchain.com/studio/?baseUrl=http://localhost:8123
  - Outil officiel pour visualiser et chatter avec vos graphs
  - Affiche les runs si `LANGSMITH_API_KEY` est dÃ©fini cÃ´tÃ© API

Notes:
- AprÃ¨s ajout dâ€™un nouvel agent, enregistrez-le dans `langgraph.json` Ã  la racine puis redÃ©marrez le service `langgraph-api`.
- Le fichier `langgraph.json` de lâ€™hÃ´te est montÃ© dans le conteneur Ã  `/app/langgraph.json`.

## ğŸ“ API Endpoints

L'API LangGraph expose plusieurs endpoints:

- `POST /runs/stream` - ExÃ©cuter un agent en streaming
- `GET /assistants` - Lister les agents disponibles
- `POST /threads` - CrÃ©er une nouvelle conversation
- `GET /threads/{thread_id}/state` - Obtenir l'Ã©tat d'une conversation

### Exemple d'appel API

```bash
curl -X POST http://localhost:8123/runs/stream \
  -H "Content-Type: application/json" \
  -d '{
    "assistant_id": "chatbot",
    "input": {
      "messages": [
        {"role": "human", "content": "Bonjour!"}
      ]
    }
  }'
```

## ğŸ› ï¸ Commandes utiles

```bash
# Voir les logs de tous les services
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f langgraph-api

# RedÃ©marrer un service
docker-compose restart langgraph-api

# ArrÃªter tout
docker-compose down

# ArrÃªter et supprimer les donnÃ©es
docker-compose down -v

# Reconstruire les images
docker-compose build --no-cache

# Voir l'Ã©tat des services
docker-compose ps
```

## ğŸ› DÃ©pannage

### L'API ne dÃ©marre pas
- VÃ©rifiez les logs: `docker-compose logs langgraph-api`
- Assurez-vous que PostgreSQL et Redis sont healthy
- VÃ©rifiez que les clÃ©s API sont configurÃ©es

### Port dÃ©jÃ  utilisÃ©
- Changez les ports dans docker-compose.yml
- Ou arrÃªtez le service qui utilise le port

### "Cannot connect to Docker daemon"
- Assurez-vous que Docker Desktop est lancÃ©
- Sur Linux: `sudo systemctl start docker`

## ğŸ”’ SÃ©curitÃ©

âš ï¸ **Cette configuration est pour le DÃ‰VELOPPEMENT uniquement!**

Pour la production:
- Activez l'authentification (`LANGGRAPH_AUTH_TYPE=bearer`)
- Utilisez HTTPS avec des certificats valides
- Configurez des mots de passe forts pour PostgreSQL
- Limitez l'accÃ¨s rÃ©seau aux services

## ğŸ“š Ressources

- [Documentation LangGraph](https://langchain-ai.github.io/langgraph/)
- [LangGraph Examples](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [LangChain Academy](https://academy.langchain.com/courses/intro-to-langgraph)

## ğŸ—ï¸ Architecture

Cette stack se compose de 5 services principaux, reliÃ©s par le rÃ©seau `langgraph-network`:

- __API LangGraph (`langgraph-api`)__: charge `langgraph.json`, expose `/runs/stream`, `/threads`, etc.
- __Redis (`langgraph-redis`)__: file d'attente interne, streaming et orchestration in-memory.
- __PostgreSQL (`langgraph-postgres`)__: persistence des runs/threads quand activÃ©e.
- __UI locale (`langgraph-ui`)__: Ã©diteur d'agents (Monaco), tests via `/runs/stream`.
- __Nginx (`langgraph-proxy`)__: proxy optionnel (CORS, routage propre).

```mermaid
graph TD
  Browser[ğŸ§‘â€ğŸ’» Browser] -->|UI HTTP| Nginx[(Nginx Proxy)]
  Nginx -->|/api -> 8123| API[LangGraph API]
  Browser -->|Direct dev| API
  API --> Redis[(Redis)]
  API --> PG[(PostgreSQL)]
  API -->|Telemetry opt| LangSmith[(LangSmith Cloud)]
```

### DÃ©couverte des Graphs (assistants)
- Au dÃ©marrage, l'API lit `langgraph.json` (dans le conteneur: `/app/langgraph.json`).
- Dans ce repo, __le fichier hÃ´te est montÃ© dans le conteneur__ via `docker-compose.yml`:
  - `- ./langgraph.json:/app/langgraph.json:ro`
- Lorsquâ€™on ajoute un nouvel agent, on lâ€™enregistre dans `langgraph.json` et on __redÃ©marre le service API__ pour relire la config.
- VÃ©rification rapide dans le conteneur:
  - `docker-compose exec langgraph-api cat /app/langgraph.json`

## ğŸ”„ Flux dâ€™exÃ©cution (Test/Chat)

```mermaid
sequenceDiagram
  participant B as Browser (UI/Studio)
  participant N as Nginx
  participant A as LangGraph API
  participant R as Redis
  participant D as Postgres
  participant LS as LangSmith (opt)

  B->>N: POST /runs/stream { assistant_id, input }
  N->>A: Proxy request
  A->>R: Enqueue + stream events
  A->>D: Persist thread/state (si activÃ©)
  A-->>B: SSE tokens / checkpoints
  A-->>LS: Metadata/telemetry (si clÃ© configurÃ©e)
```

### SchÃ©ma dâ€™Ã©tat cÃ´tÃ© agents
- Chaque agent expose `app` et un `State` avec `messages: Annotated[Sequence[AnyMessage], add_messages]`.
- Les autres champs dâ€™Ã©tat sont optionnels pour accepter `{ "messages": [...] }`.
- Le dernier nÅ“ud ajoute un `AIMessage` dans `messages` pour la compatibilitÃ© Chat.

## ğŸ’¡ Tips & Tricks

1. **Hot Reload**: Les modifications dans l'interface web sont automatiquement rechargÃ©es
2. **Multiple Agents**: CrÃ©ez autant d'agents que nÃ©cessaire dans le dossier `agents/`
3. **Partage**: Les agents peuvent Ãªtre exportÃ©s et partagÃ©s comme dossiers
